{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ea0cf-05db-4794-ab01-3673e814d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "project/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ app.py                # Main script to run the Streamlit app\n",
    "‚îú‚îÄ‚îÄ data_loader.py        # Handles loading data\n",
    "‚îú‚îÄ‚îÄ pages/                # Folder containing different pages of the app\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ about.py          # About the project page\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ summary.py        # Data summary page\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ unique_values.py  # Unique values page\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ stats.py          # Basic statistics page\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ demographics.py   # Demographics analysis page\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ duration.py       # Process duration analysis page\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ hypothesis.py     # Hypothesis testing page\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ completion.py     # Completion time analysis page\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ bounce_rate.py    # Bounce rate analysis page\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ error_rate.py     # Error rate analysis page\n",
    "‚îî‚îÄ‚îÄ utils_                # Folder for utility functions\n",
    "    ‚îú‚îÄ‚îÄ display.py        # Helper functions for displaying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eefe78b-88e2-4178-9e6e-c8f939b72634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader.py\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and return the data from the given file path.\n",
    "    Also, calculate any derived columns like `completion` and `age_group`.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data from the specified CSV file\n",
    "        df = pd.read_csv('https://raw.githubusercontent.com/simovaeliska/second_project/refs/heads/main/data/clean/combined_cleaned_data1.csv')\n",
    "        \n",
    "        # Ensure 'completion' column is calculated if not present\n",
    "        if 'completion' not in df.columns:\n",
    "            df['completion'] = df['process_step'].apply(lambda x: 1 if x in ['confirm', 'completed'] else 0)\n",
    "        \n",
    "        # Age categorization (if not already done)\n",
    "        if 'age_group' not in df.columns:\n",
    "            bins = [0, 30, 40, 50, 100] \n",
    "            labels = ['Under 30', '30-39', '40-49', '50 and above']\n",
    "            df['age_group'] = pd.cut(df['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261fcaa-122a-4112-9cba-f2acd1bc0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "import streamlit as st\n",
    "from data_loader import load_data  # Assuming load_data is in the data_loader.py file\n",
    "from pages import about, summary, unique_values, stats, demographics, hypothesistestcompletionrate, duration, completion, error_rate\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the Streamlit app for A/B Test Demo.\n",
    "    \n",
    "    Sets up the page configuration, loads data, and manages navigation\n",
    "    through different pages of the app.\n",
    "    \"\"\"\n",
    "    st.set_page_config(page_title=\"A/B Test Demo for Group 7\")\n",
    "    \n",
    "    # Provide the correct path to the CSV\n",
    "    data_path = \"path_to_your_data.csv\"  # Make sure this path is correct\n",
    "\n",
    "    # Load the data from data_loader\n",
    "    df = load_data(data_path)\n",
    "\n",
    "    if df is None:\n",
    "        st.error(\"Data could not be loaded. Please check your file path or data source.\")\n",
    "        return\n",
    "\n",
    "    # Sort the data into control and test groups\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "\n",
    "    control_group_sorted = control_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "    test_group_sorted = test_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "\n",
    "    st.sidebar.title(\"Navigation\")\n",
    "    page = st.sidebar.radio(\"Select a page:\", [\n",
    "        \"About the Project\", \n",
    "        \"Data Summary\", \n",
    "        \"Unique Values\", \n",
    "        \"Basic Statistics\", \n",
    "        \"Demographics Analysis\", \n",
    "        \"Hypothesis Testing Completion Rate\", \n",
    "        \"Process Duration Analysis\",  \n",
    "        \"Completion Time Analysis\",\n",
    "        \"Error Rate Hypothesis Testing\"\n",
    "    ])\n",
    "\n",
    "    # Handle page navigation and pass the df and sorted groups to the page\n",
    "    if page == \"About the Project\":\n",
    "        about.show_about_project()\n",
    "    elif page == \"Data Summary\":\n",
    "        summary.show_data_summary(df)\n",
    "    elif page == \"Unique Values\":\n",
    "        unique_values.show_unique_values_in_categorical_columns(df)\n",
    "    elif page == \"Basic Statistics\":\n",
    "        stats.show_basic_statistics(df)\n",
    "    elif page == \"Demographics Analysis\":\n",
    "        demographics.show_demographics(df, control_group_sorted, test_group_sorted)\n",
    "    elif page == \"Hypothesis Testing Completion Rate\":\n",
    "        hypothesistestcompletionrate.show_page(df)\n",
    "    elif page == \"Process Duration Analysis\":\n",
    "        duration.show_process_duration(df)\n",
    "    elif page == \"Completion Time Analysis\":\n",
    "        completion.show_completion_time(df)\n",
    "    elif page == \"Error Rate Hypothesis Testing\":\n",
    "        error_rate.show_error_rate_analysis(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac587d9-0515-4f5e-9652-97bc5366eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/about.py\n",
    "import streamlit as st\n",
    "from data_loader import load_data\n",
    "\n",
    "def show_about_project():\n",
    "    st.title(\"About the Project\")\n",
    "    \n",
    "    st.header(\"Project Overview by Ceci and Eliska\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        An A/B test was conducted from 3/15/2017 to 6/20/2017 by the Vanguard team to evaluate the impact of a new digital interface.\n",
    "\n",
    "        **Control Group**: Clients interacted with Vanguard‚Äôs traditional online process.  \n",
    "        **Test Group**: Clients experienced the new, spruced-up digital interface.\n",
    "\n",
    "        ### Project Timeline:\n",
    "        - **Day 1 & 2 (Week 5)**  \n",
    "          EDA & Data Cleaning  \n",
    "          Client behavior analysis ‚Äì identifying relations and forming hypotheses.\n",
    "\n",
    "        - **Day 3 (Week 5)**  \n",
    "          Performance Metrics  \n",
    "          Success Indicators  \n",
    "          Redesign Outcome\n",
    "\n",
    "        - **Day 4 & 5 (Week 5)**  \n",
    "          Hypothesis Testing  \n",
    "          Completion Rate  \n",
    "          Cost-Effectiveness Threshold  \n",
    "          Additional Hypothesis Examples  \n",
    "          Experiment Evaluation  \n",
    "          Design Effectiveness  \n",
    "          Duration Assessment  \n",
    "          Further Data Needs\n",
    "\n",
    "        - **Day 1 & 2 (Week 6)**  \n",
    "          Tableau  \n",
    "          Visualization Tasks\n",
    "\n",
    "        - **Day 3 & 4 (Week 6)**  \n",
    "          Further Data Analysis and Presentation Preparation\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # About Vanguard Group\n",
    "    st.subheader(\"About Vanguard Group\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        The Vanguard Group is one of the world‚Äôs largest investment management companies, founded in 1975 by John C. Bogle. It is renowned for pioneering low-cost index funds, which allow investors to track broad market indices with minimal fees. Vanguard‚Äôs investor-owned structure means that the company is owned by the funds it manages, aligning its interests with those of its investors. Today, Vanguard manages trillions of dollars in assets, offering a wide range of investment products including mutual funds, ETFs, and retirement plans, with a focus on long-term, passive investing strategies.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # New Sub-heading: Digital Challenge and Our Role\n",
    "    st.subheader(\"Digital Challenge and Our Role\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        **A/B Test Objective:**  \n",
    "        The goal of this experiment was to evaluate a new, modernized user interface (UI) designed to improve the online client journey through in-context prompts.\n",
    "\n",
    "        **Experiment Details:**\n",
    "        - **Control Group**: Clients used the traditional Vanguard user interface.\n",
    "        - **Test Group**: Clients experienced the new, intuitive UI with contextual prompts designed to guide them through the online process.\n",
    "\n",
    "        **Timeline:**  \n",
    "        The experiment took place from **March 15, 2017 ‚Äì June 20, 2017**.\n",
    "\n",
    "        **Process Flow:**  \n",
    "        Clients followed a sequence of steps starting from the initial page, progressing through three key steps, and finishing at the confirmation page.\n",
    "\n",
    "        *As part of the CX (Customer Experience) team, our job was to evaluate whether the new UI leads to better user engagement and higher completion rates during online processes.*\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # **Did the new UI lead to higher completion rates?**\n",
    "    st.write(\"**Did the new UI lead to higher completion rates?**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        The A/B test was designed to determine whether the new, intuitive UI with contextual prompts improved user engagement and completion rates compared to the traditional Vanguard user interface. The results from hypothesis testing and analysis will help answer this key question.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # New Section: What Data We Have Been Working With\n",
    "    st.subheader(\"What Data We Have Been Working With\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        The analysis is based on a rich set of data that provides insights into both client demographics and their digital interactions with Vanguard's platform. Below is a summary of the key datasets:\n",
    "\n",
    "        - **Client Profiles**: This includes demographic and account details such as:\n",
    "          - **Client's Age**: The age of each client.\n",
    "          - **Client's Tenure**: How long each client has been with Vanguard, in both years and months.\n",
    "          - **Client's Balance**: The total balance held across all of a client's accounts with Vanguard.\n",
    "          - **Number of Accounts**: The number of accounts the client holds with Vanguard.\n",
    "\n",
    "        - **Digital Footprints**: This data captures the client's online activity at each step in the client journey:\n",
    "          - **Process Steps**: The sequence of steps each client went through in their digital process (e.g., initial page, steps 1-3, and confirmation page).\n",
    "          - **Date-Time Logs**: Timestamps for each action taken by the client during their online session, allowing us to track the client‚Äôs progression through each step.\n",
    "\n",
    "        - **Experiment Roster**: This dataset indicates which group each client was assigned to (Control or Test), based on their unique **client_id**. It helps us compare the performance of the Control group (traditional UI) against the Test group (new UI with contextual prompts).\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # New Section: Key Performance Indicators (KPIs)\n",
    "    st.markdown(\"## **Key Performance Indicators (KPI's)**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        The following KPIs were tracked to evaluate the effectiveness of the experiment and assess user engagement:\n",
    "        \n",
    "        - **Completion Rate**: The percentage of users who completed the process flow from start to finish. This helps to evaluate whether the new interface leads to higher engagement and successful outcomes.\n",
    "        - **Engagement Metrics**:\n",
    "          - **Logins**: The frequency with which clients logged into their accounts, a measure of engagement and usage.\n",
    "          - **Calls**: The number of client service calls made, indicating the level of client support needed.\n",
    "        - **Average Account Balance**: The average balance held by clients, which provides insights into client wealth and account activity.\n",
    "        - **Tenure**: The number of years a client has been with Vanguard, reflecting client loyalty and long-term engagement.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    st.header(\"Getting Started\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        ## Metadata\n",
    "        This comprehensive set of fields will guide your analysis, helping you uncover insights into client behavior and preferences.\n",
    "\n",
    "        - **client_id**: A unique identifier for each client.\n",
    "        - **variation**: Denotes whether a client was part of the experiment (Control or Test).\n",
    "        - **visitor_id**: A unique ID for each client-device combination.\n",
    "        - **visit_id**: A unique ID for each web visit/session.\n",
    "        - **process_step**: The step in the digital process that the client is engaged in.\n",
    "        - **date_time**: Timestamp of each web activity.\n",
    "        - **clnt_tenure_yr**: The number of years a client has been with Vanguard.\n",
    "        - **clnt_tenure_mnth**: The number of months a client has been with Vanguard.\n",
    "        - **clnt_age**: The client‚Äôs age.\n",
    "        - **gendr**: The client‚Äôs gender.\n",
    "        - **num_accts**: The number of accounts the client holds with Vanguard.\n",
    "        - **bal**: The total balance across all client accounts.\n",
    "        - **calls_6_mnth**: The number of times the client reached out over the phone in the last 6 months.\n",
    "        - **logons_6_mnth**: The number of times the client logged into Vanguard‚Äôs platform over the last 6 months.\n",
    "\n",
    "        ## Bonus: Additional Tasks (Optional)\n",
    "        If you have extra time after completing the core tasks, explore the following optional questions and activities:\n",
    "\n",
    "        - **Client Behavior Analysis**: Dive deeper into the data to analyze client behavior patterns and trends.\n",
    "        - **Power and Effect Size**: Perform power analysis to determine the sample size needed for a reliable test and compute the effect size.\n",
    "        - **Streamlit Integration**: Add Streamlit widgets to your project to enable real-time analysis and visualization. Customize your app for interactivity.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # **Data Cleaning & Merging Process** section\n",
    "    st.subheader(\"Data Cleaning & Merging Process\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        The data cleaning and merging process is crucial for ensuring the integrity and consistency of the dataset. Here's how we handled the data:\n",
    "\n",
    "        **Clean Datasets**:\n",
    "        - **Load Data**: We begin by loading the raw data from various sources.\n",
    "        - **Drop Missing Values**: Any missing values in critical columns (like `client_id`, `process_step`, etc.) are removed to ensure that we only work with complete data.\n",
    "        - **Rename Columns**: Columns are renamed to have consistent naming conventions and be more meaningful for analysis.\n",
    "        - **Remove 'X' Gender Values**: Any rows with 'X' as a gender label are removed as this represents incomplete or erroneous data.\n",
    "        - **Map Gender Codes to Labels**: Gender codes are mapped to more readable labels (e.g., 'M' -> 'Male', 'F' -> 'Female').\n",
    "        - **Ensure Proper DateTime Format**: We ensure that the `date_time` column is in the correct format (i.e., datetime objects), allowing for time-based analysis.\n",
    "\n",
    "        **Merge Datasets**:\n",
    "        - **Merge Demographic Datasets**: We combine the demographic data (client information such as age, tenure, balance) into a single dataset.\n",
    "        - **Concatenate Web Interactions Dataset**: The web interactions (client's steps through the online process) are merged with the demographic data based on the `client_id`.\n",
    "        - **Final Merge on `client_id`**: After all data is cleaned and preprocessed, we merge all datasets on the common `client_id` column to create a comprehensive dataset.\n",
    "\n",
    "        **Segment by Experiment Group**:\n",
    "        - **Control and Test Groups**: The dataset is split into two groups based on the `variation` column: the Control group (clients using the traditional UI) and the Test group (clients using the new UI with contextual prompts).\n",
    "\n",
    "        **Sort Data**:\n",
    "        - **Sort by client_id, visit_id, process_step, and date_time**: This ensures that the data is ordered by the client's journey through the process, from their first visit to the confirmation step.\n",
    "\n",
    "        **Age Group Categorization**:\n",
    "        - **Assign Age Groups**: Based on defined age bins, we categorize clients into age groups (e.g., under 30, 30-39, 40-49, 50+). This categorization is applied to the `df_merged`, as well as to the `control` and `test` datasets to facilitate age-based analysis.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # **Who are our clients?** section\n",
    "    st.subheader(\"Who Are Our Clients?\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        For demographic analysis, we worked with a pool of **70,591 users** after applying the cleaning and merging processes to ensure data quality.\n",
    "\n",
    "        **Group with highest average tenure and balance**:\n",
    "        - **Gender**: Male\n",
    "        - **Age Group**: 50 and above\n",
    "        - **Client's Tenure**: 16.35 years\n",
    "        - **Balance**: 294,239.72$\n",
    "        **Average Persona**:\n",
    "        - **Gender**: Male\n",
    "        - **Age Group**: 30-39\n",
    "        - **Average Tenure**: 11.65 years\n",
    "        - **Average Balance**: 126,284.41$\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # **Further Observations** section\n",
    "    st.subheader(\"Further Observations\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        - Males generally have higher average balances than females, with the highest balances observed in the \"50 and above\" age group for both genders.\n",
    "        - Both males and females show similar tenure patterns, with longer tenures seen in older age groups (50+ years), indicating long-term clients.\n",
    "        - The ‚ÄúUnknown\" gender category typically has lower average balances, likely due to potential data gaps or non-disclosure of gender.\n",
    "        \"\"\"\n",
    "    )\n",
    "    # **Did the new UI lead to higher completion rates?**\n",
    "    st.write(\"**Did the new UI lead to higher completion rates?**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        The A/B test was designed to determine whether the new, intuitive UI with contextual prompts improved user engagement and completion rates compared to the traditional Vanguard user interface. The results from hypothesis testing and analysis will help answer this key question.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # New Section: What Data We Have Been Working With\n",
    "    st.subheader(\"What Data We Have Been Working With\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        The analysis is based on a rich set of data that provides insights into both client demographics and their digital interactions with Vanguard's platform. Below is a summary of the key datasets:\n",
    "\n",
    "        - **Client Profiles**: This includes demographic and account details such as:\n",
    "          - **Client's Age**: The age of each client.\n",
    "          - **Client's Tenure**: How long each client has been with Vanguard, in both years and months.\n",
    "          - **Client's Balance**: The total balance held across all of a client's accounts with Vanguard.\n",
    "          - **Number of Accounts**: The number of accounts the client holds with Vanguard.\n",
    "\n",
    "        - **Digital Footprints**: This data captures the client's online activity at each step in the client journey:\n",
    "          - **Process Steps**: The sequence of steps each client went through in their digital process (e.g., initial page, steps 1-3, and confirmation page).\n",
    "          - **Date-Time Logs**: Timestamps for each action taken by the client during their online session, allowing us to track the client‚Äôs progression through each step.\n",
    "\n",
    "        - **Experiment Roster**: This dataset indicates which group each client was assigned to (Control or Test), based on their unique **client_id**. It helps us compare the performance of the Control group (traditional UI) against the Test group (new UI with contextual prompts).\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # New Section: Key Performance Indicators (KPIs)\n",
    "    st.markdown(\"## **Key Performance Indicators (KPI's)**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        The following KPIs were tracked to evaluate the effectiveness of the experiment and assess user engagement:\n",
    "        \n",
    "        - **Completion Rate**: The percentage of users who completed the process flow from start to finish. This helps to evaluate whether the new interface leads to higher engagement and successful outcomes.\n",
    "        - **Engagement Metrics**:\n",
    "          - **Logins**: The frequency with which clients logged into their accounts, a measure of engagement and usage.\n",
    "          - **Calls**: The number of client service calls made, indicating the level of client support needed.\n",
    "        - **Average Account Balance**: The average balance held by clients, which provides insights into client wealth and account activity.\n",
    "        - **Tenure**: The number of years a client has been with Vanguard, reflecting client loyalty and long-term engagement.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    st.header(\"Getting Started\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        ## Metadata\n",
    "        This comprehensive set of fields will guide your analysis, helping you uncover insights into client behavior and preferences.\n",
    "\n",
    "        - **client_id**: A unique identifier for each client.\n",
    "        - **variation**: Denotes whether a client was part of the experiment (Control or Test).\n",
    "        - **visitor_id**: A unique ID for each client-device combination.\n",
    "        - **visit_id**: A unique ID for each web visit/session.\n",
    "        - **process_step**: The step in the digital process that the client is engaged in.\n",
    "        - **date_time**: Timestamp of each web activity.\n",
    "        - **clnt_tenure_yr**: The number of years a client has been with Vanguard.\n",
    "        - **clnt_tenure_mnth**: The number of months a client has been with Vanguard.\n",
    "        - **clnt_age**: The client‚Äôs age.\n",
    "        - **gendr**: The client‚Äôs gender.\n",
    "        - **num_accts**: The number of accounts the client holds with Vanguard.\n",
    "        - **bal**: The total balance across all client accounts.\n",
    "        - **calls_6_mnth**: The number of times the client reached out over the phone in the last 6 months.\n",
    "        - **logons_6_mnth**: The number of times the client logged into Vanguard‚Äôs platform over the last 6 months.\n",
    "\n",
    "        ## Bonus: Additional Tasks (Optional)\n",
    "        If you have extra time after completing the core tasks, explore the following optional questions and activities:\n",
    "\n",
    "        - **Client Behavior Analysis**: Dive deeper into the data to analyze client behavior patterns and trends.\n",
    "        - **Power and Effect Size**: Perform power analysis to determine the sample size needed for a reliable test and compute the effect size.\n",
    "        - **Streamlit Integration**: Add Streamlit widgets to your project to enable real-time analysis and visualization. Customize your app for interactivity.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # **Data Cleaning & Merging Process** section\n",
    "    st.subheader(\"Data Cleaning & Merging Process\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        The data cleaning and merging process is crucial for ensuring the integrity and consistency of the dataset. Here's how we handled the data:\n",
    "\n",
    "        **Clean Datasets**:\n",
    "        - **Load Data**: We begin by loading the raw data from various sources.\n",
    "        - **Drop Missing Values**: Any missing values in critical columns (like `client_id`, `process_step`, etc.) are removed to ensure that we only work with complete data.\n",
    "        - **Rename Columns**: Columns are renamed to have consistent naming conventions and be more meaningful for analysis.\n",
    "        - **Remove 'X' Gender Values**: Any rows with 'X' as a gender label are removed as this represents incomplete or erroneous data.\n",
    "        - **Map Gender Codes to Labels**: Gender codes are mapped to more readable labels (e.g., 'M' -> 'Male', 'F' -> 'Female').\n",
    "        - **Ensure Proper DateTime Format**: We ensure that the `date_time` column is in the correct format (i.e., datetime objects), allowing for time-based analysis.\n",
    "\n",
    "        **Merge Datasets**:\n",
    "        - **Merge Demographic Datasets**: We combine the demographic data (client information such as age, tenure, balance) into a single dataset.\n",
    "        - **Concatenate Web Interactions Dataset**: The web interactions (client's steps through the online process) are merged with the demographic data based on the `client_id`.\n",
    "        - **Final Merge on `client_id`**: After all data is cleaned and preprocessed, we merge all datasets on the common `client_id` column to create a comprehensive dataset.\n",
    "\n",
    "        **Segment by Experiment Group**:\n",
    "        - **Control and Test Groups**: The dataset is split into two groups based on the `variation` column: the Control group (clients using the traditional UI) and the Test group (clients using the new UI with contextual prompts).\n",
    "\n",
    "        **Sort Data**:\n",
    "        - **Sort by client_id, visit_id, process_step, and date_time**: This ensures that the data is ordered by the client's journey through the process, from their first visit to the confirmation step.\n",
    "\n",
    "        **Age Group Categorization**:\n",
    "        - **Assign Age Groups**: Based on defined age bins, we categorize clients into age groups (e.g., under 30, 30-39, 40-49, 50+). This categorization is applied to the `df_merged`, as well as to the `control` and `test` datasets to facilitate age-based analysis.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # **Who are our clients?** section\n",
    "    st.subheader(\"Who Are Our Clients?\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        For demographic analysis, we worked with a pool of **70,591 users** after applying the cleaning and merging processes to ensure data quality.\n",
    "\n",
    "        **Group with highest average tenure and balance**:\n",
    "        - **Gender**: Male\n",
    "        - **Age Group**: 50 and above\n",
    "        - **Client's Tenure**: 16.35 years\n",
    "        - **Balance**: 294,239.72$\n",
    "        **Average Persona**:\n",
    "        - **Gender**: Male\n",
    "        - **Age Group**: 30-39\n",
    "        - **Average Tenure**: 11.65 years\n",
    "        - **Average Balance**: 126,284.41$\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # **Further Observations** section\n",
    "    st.subheader(\"Further Observations\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        - Males generally have higher average balances than females, with the highest balances observed in the \"50 and above\" age group for both genders.\n",
    "        - Both males and females show similar tenure patterns, with longer tenures seen in older age groups (50+ years), indicating long-term clients.\n",
    "        - The ‚ÄúUnknown\" gender category typically has lower average balances, likely due to potential data gaps or non-disclosure of gender.\n",
    "        \"\"\"\n",
    "    )\n",
    "    # New Section: Key Performance Indicators (KPIs)\n",
    "    st.markdown(\"## **Key Performance Indicators (KPI's)**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        The following KPIs were tracked to evaluate the effectiveness of the experiment and assess user engagement:\n",
    "        \n",
    "        - **Completion Rate**: The percentage of users who completed the process flow from start to finish. This helps to evaluate whether the new interface leads to higher engagement and successful outcomes.\n",
    "        - **Engagement Metrics**:\n",
    "          - **Logins**: The frequency with which clients logged into their accounts, a measure of engagement and usage.\n",
    "          - **Calls**: The number of client service calls made, indicating the level of client support needed.\n",
    "        - **Average Account Balance**: The average balance held by clients, which provides insights into client wealth and account activity.\n",
    "        - **Tenure**: The number of years a client has been with Vanguard, reflecting client loyalty and long-term engagement.\n",
    "        \n",
    "        ### Additional Insights:\n",
    "        \n",
    "        - **Completion Rate**:  \n",
    "          If the **Test group** shows a higher completion rate compared to the **Control group**, it suggests that the new design has improved user engagement, making it easier for users to complete the process. This could indicate that the intuitive interface or contextual prompts helped users to feel more confident and successful in completing the steps.\n",
    "\n",
    "        - **Time Spent on Each Step**:  \n",
    "          A lower time spent at each step in the **Test group** compared to the **Control group** would suggest that the new design is more efficient. This can be interpreted as users moving through the process more quickly, likely due to the improved clarity or guidance offered by the new UI design.\n",
    "\n",
    "        - **Error Rates**:  \n",
    "          A reduction in error rates in the **Test group** would suggest that the new design is more intuitive and user-friendly. This could mean that fewer users encountered confusion or made mistakes during the process, likely because the contextual prompts and simplified steps helped guide them more effectively.\n",
    "\n",
    "        - **Bounce Rates**:  \n",
    "          If the **Test group** has a lower bounce rate compared to the **Control group**, it suggests that the new design is better at keeping users engaged throughout the process. A lower bounce rate would indicate that users are more likely to stay in the process, reducing drop-offs or exits at any given step, which is a good indicator of user retention and interest.\n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "        # New Section: Tableau Visuals\n",
    "    st.markdown(\"## **Tableau Visuals**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        You can explore the interactive Tableau dashboard for further insights into the data and visualizations by following the link below:\n",
    "        \n",
    "        [**Vanguard CX Story**](https://public.tableau.com/app/profile/eliska.simova/viz/Vanguard_CX/Vanguard_story?publish=yes)\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # New Section: Hypothesis Testing\n",
    "    st.markdown(\"## **Hypothesis Testing**\")\n",
    "    \n",
    "    # Hypothesis 1\n",
    "    st.subheader(\"Hypothesis 1: Completion Rate Comparison\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        **Hypothesis**: \"Is there a significant difference in the completion rates between the Control group and the Test group at each step of the process?\"\n",
    "\n",
    "        - All steps show statistically significant differences in completion rates between the **Test group** (new UI) and **Control group** (old UI).\n",
    "        - A **p-value of 0.0000** for each step indicates strong evidence against the null hypothesis.\n",
    "        - We **reject the null hypothesis** at all steps, meaning that the new design does indeed have a significantly different impact on user completion rates at each step compared to the old design.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Hypothesis 2\n",
    "    st.subheader(\"Hypothesis 2: Completion Rate Increase\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        **Hypothesis**: \"Does the introduction of the new UI design result in a minimum 5% increase in the completion rate compared to the existing design, making it cost-effective?\"\n",
    "\n",
    "        - The completion rate increase of **9.82%** between the **Test** and **Control** groups exceeds the **5%** threshold set by Vanguard.\n",
    "        - The **new UI design** could be considered **worthwhile from a business perspective** due to this significant increase in the completion rate.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Hypothesis 3\n",
    "    st.subheader(\"Hypothesis 3: Average Client Tenure Comparison\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        **Hypothesis**: \"Is the average client tenure of those engaging with the new process the same as those engaging with the old process?\"\n",
    "\n",
    "        - **Control Group Average Tenure**: 12.09 years\n",
    "        - **Test Group Average Tenure**: 11.98 years\n",
    "        - **p-value**: 0.0868, **Statistic**: 1.7124 (indicates how much the means differ relative to variability)\n",
    "        - We **fail to reject the null hypothesis**, meaning the **average tenure is not significantly different** between the two groups.\n",
    "        - The lack of significant difference in **average tenure** supports the validity of the A/B test results.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Hypothesis 4\n",
    "    st.subheader(\"Hypothesis 4: Average Client Age Comparison\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        **Hypothesis**: \"Is the average client age of those engaging with the new process the same as those engaging with the old process?\"\n",
    "\n",
    "        - **Control Average Age**: 47.50 years\n",
    "        - **Test Average Age**: 47.16 years\n",
    "        - **p-value**: 0.0160\n",
    "        - Since the **p-value is less than 0.05**, we **reject the null hypothesis**, indicating that there is a **statistical difference** in the average age between the Test and Control groups.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Hypothesis 5\n",
    "    st.subheader(\"Hypothesis 5: Error Rate Comparison\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        **Hypothesis**: \"Does the new UI design lead to a reduction in error rates compared to the old design, and is this reduction statistically significant?\"\n",
    "\n",
    "        - **Control Error Rate**: 19.21%\n",
    "        - **Test Error Rate**: 17.64%\n",
    "        - **Percentage Difference**: 1.57%\n",
    "        - **p-value**: 0.0000\n",
    "        - We **reject the null hypothesis** that there is no difference between the groups, indicating that the **new UI** has a **significantly lower error rate** than the old UI.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Hypothesis 6\n",
    "    st.subheader(\"Hypothesis 6: Bounce Rate Comparison\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        **Hypothesis**: ‚ÄúIs the bounce rate of the Test group lower than the Control group across all steps?‚Äù\n",
    "\n",
    "        - The **Test group** showed a **statistically significant lower bounce rate** only at **Step 1**.\n",
    "        - For **Steps 0**, **2**, and **3**, there were **no statistically significant differences** between the Control and Test groups.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # New Section: Experiment Evaluation\n",
    "    st.markdown(\"## **Experiment Evaluation**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        - **Average Ages**: The average age is statistically different between the Test and Control groups, as indicated by the **p-value of 0.0160**, which is less than the **0.05 threshold**.\n",
    "        - This means the distribution of **ages** between the two groups is **not uniform**, and age differences could potentially introduce a **bias in the observed completion rate**.\n",
    "        \"\"\"\n",
    "    )\n",
    "    # New Section: Recommendations\n",
    "    st.markdown(\"## **_Recommendations_**\")\n",
    "    \n",
    "    # Recommendation 1\n",
    "    st.subheader(\"1. **Simplify the Process**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        All age groups may benefit from a more straightforward flow.\n",
    "\n",
    "        üí° **Reduce unnecessary steps and minimize user decisions to streamline the experience**.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Recommendation 2\n",
    "    st.subheader(\"2. **Provide Contextual Help**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        High bounce rates may suggest confusion or hesitation; users might benefit from guidance or support.\n",
    "\n",
    "        üí° **Add tooltips, help icons, and live support to guide users**.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Recommendation 3\n",
    "    st.subheader(\"3. **Improve Visual Design**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        Bounce rates at certain steps suggest that users might find some of the content unclear.\n",
    "\n",
    "        üí° **Ensure readability and consistency in font size, contrast, and button design**.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Recommendation 4\n",
    "    st.subheader(\"4. **Personalize Experience**\")\n",
    "    st.write(\n",
    "        \"\"\"\n",
    "        Users might lose track of where they are in the process or forget to complete it.\n",
    "\n",
    "        üí° **Offer reminders and allow users to save their progress for later completion**.\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3681c68-b2ee-4da8-9724-34bb380d5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/summary.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from data_loader import load_data\n",
    "\n",
    "def show_data_summary(df):\n",
    "    st.subheader(\"CSV Data Overview\")\n",
    "    st.write(f\"Number of rows: {df.shape[0]}\")\n",
    "    st.write(f\"Number of columns: {df.shape[1]}\")\n",
    "    st.write(\"First 5 rows of the dataset:\")\n",
    "    st.dataframe(df.head())\n",
    "\n",
    "# Assuming you're loading your data in the main part of the app or another script\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: loading a CSV file\n",
    "    # Change the path below to your actual file location\n",
    "    df = pd.read_csv(\"path_to_your_data.csv\")  # Load data from CSV\n",
    "\n",
    "    # Now call the function and pass the DataFrame `df`\n",
    "    show_data_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54682bf2-005a-4981-b477-8c8e2c1b2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/unique_values.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from data_loader import load_data\n",
    "\n",
    "def show_unique_values_in_categorical_columns(df):\n",
    "    st.title(\"Unique Values in Categorical Columns\")\n",
    "    \n",
    "    # Get all categorical columns\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Check if there are any categorical columns\n",
    "    if not categorical_columns:\n",
    "        st.warning(\"No categorical columns found in the file.\")\n",
    "        return\n",
    "\n",
    "    st.subheader(\"Unique Values in Categorical Columns:\")\n",
    "    for column in categorical_columns:\n",
    "        # Get unique values for each categorical column\n",
    "        unique_values = df[column].unique()\n",
    "        st.write(f\"Column: {column}\")\n",
    "        st.write(f\"Unique values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8d855-837d-4d90-86bb-b20fca75d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/stats.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from data_loader import load_data\n",
    "\n",
    "def show_basic_statistics(df):\n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "    # Check if there are numeric columns\n",
    "    if numeric_df.empty:\n",
    "        st.warning(\"No numeric columns found in the file.\")\n",
    "        return\n",
    "    \n",
    "    # Display basic statistics for numeric columns\n",
    "    st.subheader(\"Basic Statistics for Numeric Columns:\")\n",
    "    statistics = numeric_df.describe().T  # Transpose for better readability\n",
    "    st.write(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05f09f-8944-4883-b02c-186be28ada98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages/demographics.py\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from data_loader import load_data\n",
    "\n",
    "# Function to perform demographic analysis\n",
    "def analyze_demographics(df, control_group_sorted, test_group_sorted):\n",
    "    \"\"\"\n",
    "    Function to perform demographic analysis and generate interactive plots using Plotly.\n",
    "    \"\"\"\n",
    "    # Ensure 'clnt_age' is present and numeric\n",
    "    if 'clnt_age' not in df.columns:\n",
    "        st.error(\"The DataFrame does not contain the 'clnt_age' column.\")\n",
    "        return\n",
    "\n",
    "    if not pd.api.types.is_numeric_dtype(df['clnt_age']):\n",
    "        st.error(\"The 'clnt_age' column is not numeric.\")\n",
    "        return\n",
    "\n",
    "    # Create the 'age_group' column based on 'clnt_age' ranges\n",
    "    bins = [0, 18, 30, 40, 50, 60, 100]  # Define the age group ranges\n",
    "    labels = ['0-18', '19-30', '31-40', '41-50', '51-60', '60+']  # Age group labels\n",
    "    df['age_group'] = pd.cut(df['clnt_age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    # Debugging: Show first few rows of the dataframe to confirm 'age_group' column\n",
    "    st.write(\"First few rows of the dataframe with 'age_group':\")\n",
    "    st.write(df[['clnt_age', 'age_group']].head())\n",
    "\n",
    "    # Check if 'age_group' column exists now\n",
    "    if 'age_group' not in df.columns:\n",
    "        st.error(\"The 'age_group' column was not created.\")\n",
    "        return\n",
    "\n",
    "    # Aggregating based on 'gender' and 'age_group'\n",
    "    logs_calls_accounts = df.groupby(['gender', 'age_group']).agg({\n",
    "        'num_accts': 'mean',\n",
    "        'calls_6_mnth': 'mean',\n",
    "        'logons_6_mnth': 'mean'\n",
    "    }).reset_index().round(2)\n",
    "\n",
    "    # Debugging: Show the aggregated result\n",
    "    st.write(\"Aggregated data (grouped by 'gender' and 'age_group'):\")\n",
    "    st.write(logs_calls_accounts)\n",
    "\n",
    "    # Plot for Average Number of Accounts\n",
    "    fig1 = px.line(\n",
    "        logs_calls_accounts, \n",
    "        x='age_group', \n",
    "        y='num_accts', \n",
    "        color='gender',\n",
    "        title=\"Average Number of Accounts by Age Group and Gender\",\n",
    "        labels={'num_accts': 'Average Number of Accounts'},\n",
    "        markers=True\n",
    "    )\n",
    "    st.plotly_chart(fig1)\n",
    "\n",
    "    # Plot for Calls in the Last 6 Months\n",
    "    fig2 = px.line(\n",
    "        logs_calls_accounts, \n",
    "        x='age_group', \n",
    "        y='calls_6_mnth', \n",
    "        color='gender',\n",
    "        title=\"Average Calls in Last 6 Months by Age Group and Gender\",\n",
    "        labels={'calls_6_mnth': 'Average Calls in Last 6 Months'},\n",
    "        line_shape='linear',\n",
    "        markers=True\n",
    "    )\n",
    "    st.plotly_chart(fig2)\n",
    "\n",
    "    # Plot for Logons in the Last 6 Months\n",
    "    fig3 = px.line(\n",
    "        logs_calls_accounts, \n",
    "        x='age_group', \n",
    "        y='logons_6_mnth', \n",
    "        color='gender',\n",
    "        title=\"Average Logons in Last 6 Months by Age Group and Gender\",\n",
    "        labels={'logons_6_mnth': 'Average Logons in Last 6 Months'},\n",
    "        line_shape='linear',\n",
    "        markers=True\n",
    "    )\n",
    "    st.plotly_chart(fig3)\n",
    "\n",
    "    # *** Age Group by Test & Control ***\n",
    "    st.write(\"### Test & Control Grouped by Age Group\")\n",
    "    # Filter based on unique client_id in control and test groups\n",
    "    control_unique = control_group_sorted.drop_duplicates(subset='client_id')\n",
    "    test_unique = test_group_sorted.drop_duplicates(subset='client_id')\n",
    "\n",
    "    # Calculate age group distribution for each group\n",
    "    control_age_group = control_unique[\"age_group\"].value_counts()\n",
    "    test_age_group = test_unique[\"age_group\"].value_counts()\n",
    "\n",
    "    # Combine data into one table\n",
    "    age_groups_concat = pd.concat(\n",
    "        [control_age_group, test_age_group], \n",
    "        axis=1, \n",
    "        keys=[\"Control Group Count\", \"Test Group Count\"]\n",
    "    )\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    age_groups_concat = age_groups_concat.sort_values(by=\"age_group\", ascending=True)  # sort values\n",
    "    age_groups_concat = age_groups_concat.reset_index()\n",
    "\n",
    "    st.write(age_groups_concat)\n",
    "\n",
    "    # *** Age Group x Gender ***\n",
    "    st.write(\"### Age Group x Gender\")\n",
    "    control_age_group_gender = control_unique.groupby(\"age_group\")[\"gender\"].value_counts().unstack()\n",
    "    test_age_group_gender = test_unique.groupby(\"age_group\")[\"gender\"].value_counts().unstack()\n",
    "\n",
    "    # Reset the index to create a proper DataFrame structure\n",
    "    control_age_group_gender = control_age_group_gender.reset_index()\n",
    "    test_age_group_gender = test_age_group_gender.reset_index()\n",
    "\n",
    "    st.write(\"Control Group - Age Group x Gender:\")\n",
    "    st.write(control_age_group_gender)\n",
    "\n",
    "    st.write(\"Test Group - Age Group x Gender:\")\n",
    "    st.write(test_age_group_gender)\n",
    "\n",
    "    # *** Age Group x Balances ***\n",
    "    st.write(\"### Age Group x Balances\")\n",
    "    # Filter control and test group based on unique client_id\n",
    "    control_age_group_balance = control_unique.groupby(\"age_group\")[\"balance\"].mean().round(2)\n",
    "    test_age_group_balance = test_unique.groupby(\"age_group\")[\"balance\"].mean().round(2)\n",
    "\n",
    "    # Convert the grouped Series to DataFrames\n",
    "    control_age_group_balance_df = control_age_group_balance.reset_index()\n",
    "    test_age_group_balance_df = test_age_group_balance.reset_index()\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    control_age_group_balance_df.rename(columns={\"age_group\": \"Age Group\", \"balance\": \"Control Group Balance\"}, inplace=True)\n",
    "    test_age_group_balance_df.rename(columns={\"age_group\": \"Age Group\", \"balance\": \"Test Group Balance\"}, inplace=True)\n",
    "\n",
    "    # Merge both control and test balance data into a single table\n",
    "    balance_concat = pd.merge(control_age_group_balance_df, test_age_group_balance_df, on=\"Age Group\")\n",
    "\n",
    "    st.write(balance_concat)\n",
    "\n",
    "# Function to display the demographics analysis in Streamlit\n",
    "def show_demographics(df, control_group_sorted, test_group_sorted):\n",
    "    \"\"\"\n",
    "    Show Demographics Analysis in the Streamlit app.\n",
    "    This function is used to call the analysis and display the results.\n",
    "    \"\"\"\n",
    "    st.title(\"Demographics Analysis\")\n",
    "\n",
    "    # Perform the demographic analysis (aggregation and plotting)\n",
    "    analyze_demographics(df, control_group_sorted, test_group_sorted)\n",
    "\n",
    "    # Additional notes or user guidance\n",
    "    st.write(\"\"\"\n",
    "        This page provides demographic analysis, including average number of accounts, calls, \n",
    "        and logons, based on age groups and gender. The plots above allow you to explore how \n",
    "        these variables differ across age groups and between genders.\n",
    "    \"\"\")\n",
    "\n",
    "# Sorting Control and Test Groups in the main app.py or wherever necessary:\n",
    "def sort_groups(df_merged):\n",
    "    \"\"\"\n",
    "    Function to sort control and test groups based on client_id, visit_id, process_step, and date_time.\n",
    "    \"\"\"\n",
    "    control_group = df_merged[df_merged['variation'] == 'Control']\n",
    "    test_group = df_merged[df_merged['variation'] == 'Test']\n",
    "\n",
    "    # Sort control group\n",
    "    control_group_sorted = control_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "\n",
    "    # Sort test group\n",
    "    test_group_sorted = test_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "\n",
    "    return control_group_sorted, test_group_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea870251-9993-4d5f-97f8-25d6052fc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/duration.py\n",
    "import streamlit as st\n",
    "import pandas as pd  # Ensure pandas is imported\n",
    "from data_loader import load_data\n",
    "\n",
    "def show_process_duration(df):\n",
    "    st.title(\"Process Duration Analysis\")\n",
    "    \n",
    "    # Check if the necessary columns exist\n",
    "    if 'process_step' not in df.columns or 'date_time' not in df.columns or 'client_id' not in df.columns:\n",
    "        st.error(\"Missing required columns: 'process_step', 'date_time', or 'client_id'.\")\n",
    "        return\n",
    "    \n",
    "    # Define the custom sorting order for the process steps\n",
    "    process_step_order = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "    df['process_step'] = pd.Categorical(df['process_step'], categories=process_step_order, ordered=True)\n",
    "\n",
    "    # Filter groups based on test/control\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "\n",
    "    # Sort control group and test group\n",
    "    control_group_sorted = control_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "    test_group_sorted = test_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "\n",
    "    # Function to get the latest starts\n",
    "    def filter_latest_starts(group_df):\n",
    "        starts_only = group_df[group_df['process_step'] == 'start']\n",
    "        latest_starts = starts_only.loc[starts_only.groupby('visit_id')['date_time'].idxmax()]\n",
    "        return group_df.merge(latest_starts[['visit_id', 'date_time']], on=['visit_id', 'date_time'], how='inner')\n",
    "\n",
    "    # Apply to both groups (Control and Test)\n",
    "    filtered_control = filter_latest_starts(control_group_sorted)\n",
    "    filtered_test = filter_latest_starts(test_group_sorted)\n",
    "\n",
    "    # Display the complete tables for the filtered groups\n",
    "    st.title(\"Control Group Sorted and Filtered\")\n",
    "    st.dataframe(filtered_control)\n",
    "\n",
    "    st.title(\"Test Group Sorted and Filtered\")\n",
    "    st.dataframe(filtered_test)\n",
    "\n",
    "    # Check if it works for a specific client (e.g., client_id == 2304905)\n",
    "    client_total_entries = df[df[\"client_id\"] == 2304905]\n",
    "    client_last_start_control = filtered_control[filtered_control['client_id'] == 2304905]\n",
    "    client_last_start_test = filtered_test[filtered_test['client_id'] == 2304905]\n",
    "\n",
    "    # Display the results for the specific client\n",
    "    st.title(\"Total Entries for Client 2304905\")\n",
    "    st.dataframe(client_total_entries)\n",
    "\n",
    "    st.title(\"Last Start for Client 2304905 in Control Group\")\n",
    "    st.dataframe(client_last_start_control)\n",
    "\n",
    "    st.title(\"Last Start for Client 2304905 in Test Group\")\n",
    "    st.dataframe(client_last_start_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba62f24e-2582-4382-9a4f-d7b41d32868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/hypothesistestcompletionrate.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats  # Correct import for statistical functions\n",
    "import streamlit as st\n",
    "\n",
    "# Function to perform a two-proportion z-test\n",
    "def two_proportion_z_test(p1, p2, n1, n2):\n",
    "    \"\"\"\n",
    "    Perform two-proportion z-test to compare completion rates between two groups.\n",
    "    Args:\n",
    "        p1, p2: Completion proportions of control and test groups.\n",
    "        n1, n2: Sample sizes for control and test groups.\n",
    "    Returns:\n",
    "        z-statistic and p-value of the z-test.\n",
    "    \"\"\"\n",
    "    # Calculate pooled proportion\n",
    "    P = (p1 * n1 + p2 * n2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate the standard error\n",
    "    SE = np.sqrt(P * (1 - P) * (1 / n1 + 1 / n2))\n",
    "    \n",
    "    # Calculate the z-statistic\n",
    "    z = (p1 - p2) / SE\n",
    "    \n",
    "    # Calculate the p-value (two-tailed test) using scipy.stats.norm\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))  # Corrected here\n",
    "    \n",
    "    return z, p_value\n",
    "\n",
    "# Show the hypothesis testing page\n",
    "def show_page(df):\n",
    "    \"\"\"\n",
    "    Show the hypothesis testing page with completion rate analysis.\n",
    "    Args:\n",
    "        df: The dataframe containing the data\n",
    "    \"\"\"\n",
    "    # Sort the data by variation and other relevant columns\n",
    "    df_sorted = df.sort_values(by=['variation', 'client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "\n",
    "    # Define 'completion' column if not already defined (this should already be defined in data_loader.py)\n",
    "    if 'completion' not in df_sorted.columns:\n",
    "        df_sorted['completion'] = df_sorted['process_step'].apply(lambda x: 1 if x in ['confirm', 'completed'] else 0)\n",
    "\n",
    "    # Define age bins and categorize ages\n",
    "    bins = [0, 30, 40, 50, 100]  # Adjust intervals as necessary\n",
    "    labels = ['Under 30', '30-39', '40-49', '50 and above']\n",
    "    df_sorted['age_group'] = pd.cut(df_sorted['clnt_age'], bins=bins, labels=labels)\n",
    "\n",
    "    # Define process steps for hypothesis testing\n",
    "    steps = ['confirm', 'step_1', 'step_2', 'step_3']\n",
    "\n",
    "    # Create an empty list to store results\n",
    "    results = []\n",
    "\n",
    "    # Hypothesis testing for each process step\n",
    "    for step in steps:\n",
    "        # Filter data for the current process step in control and test groups\n",
    "        control_completions = df_sorted[(df_sorted['process_step'] == step) & (df_sorted['variation'] == 'Control')]['completion'].mean() * 100  # Completion rate (%) for control group\n",
    "        test_completions = df_sorted[(df_sorted['process_step'] == step) & (df_sorted['variation'] == 'Test')]['completion'].mean() * 100  # Completion rate (%) for test group\n",
    "\n",
    "        control_total = df_sorted[(df_sorted['process_step'] == step) & (df_sorted['variation'] == 'Control')].shape[0]\n",
    "        test_total = df_sorted[(df_sorted['process_step'] == step) & (df_sorted['variation'] == 'Test')].shape[0]\n",
    "\n",
    "        # Convert completion rate to proportion\n",
    "        p_control = control_completions / 100\n",
    "        p_test = test_completions / 100\n",
    "        \n",
    "        # Perform two-proportion z-test\n",
    "        z_stat, p_value = two_proportion_z_test(p_control, p_test, control_total, test_total)\n",
    "        \n",
    "        # Store the results for each step\n",
    "        results.append({\n",
    "            'Step': step,\n",
    "            'Control Completion Rate': control_completions,\n",
    "            'Test Completion Rate': test_completions,\n",
    "            'Z-statistic': z_stat,\n",
    "            'P-value': p_value,\n",
    "            'Significant': p_value < 0.05\n",
    "        })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Display the results\n",
    "    st.subheader(\"Hypothesis Testing Results for Completion Rates by Step\")\n",
    "    st.dataframe(results_df)\n",
    "\n",
    "    # Interpret the results for each step\n",
    "    for idx, row in results_df.iterrows():\n",
    "        if row['Significant']:\n",
    "            st.write(f\"**Step: {row['Step']}** - The difference in completion rates between control and test groups is statistically significant (Z = {row['Z-statistic']:.4f}, P = {row['P-value']:.4f}).\")\n",
    "        else:\n",
    "            st.write(f\"**Step: {row['Step']}** - There is no significant difference in completion rates between control and test groups (Z = {row['Z-statistic']:.4f}, P = {row['P-value']:.4f}).\")\n",
    "\n",
    "    # Average completion rates comparison (as previously done)\n",
    "    control_mean = df_sorted[df_sorted['variation'] == 'Control']['completion'].mean() * 100\n",
    "    test_mean = df_sorted[df_sorted['variation'] == 'Test']['completion'].mean() * 100\n",
    "    _, p_value = stats.ttest_ind(df_sorted[df_sorted['variation'] == 'Control']['completion'], df_sorted[df_sorted['variation'] == 'Test']['completion'], alternative='two-sided')\n",
    "\n",
    "    st.subheader(\"Average Completion Rate Comparison\")\n",
    "    st.write(f\"Average completion rate for Control group: {control_mean:.2f}%\")\n",
    "    st.write(f\"Average completion rate for Test group: {test_mean:.2f}%\")\n",
    "    st.write(f\"T-statistic: {_:.4f}\")\n",
    "    st.write(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        st.write(\"**Reject the null hypothesis**: The completion rates are significantly different between the Test and Control groups.\")\n",
    "    else:\n",
    "        st.write(\"**Fail to reject the null hypothesis**: The completion rates are not significantly different between the Test and Control groups.\")\n",
    "\n",
    "    completion_rate_increase = test_mean - control_mean\n",
    "    st.write(f\"Completion rate increase: {completion_rate_increase:.2f}%\")\n",
    "    if completion_rate_increase >= 5:\n",
    "        st.write(\"The completion rate increase meets the 5% threshold, justifying the cost of the new design.\")\n",
    "    else:\n",
    "        st.write(\"The completion rate increase does not meet the 5% threshold. The new design may not justify its cost.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b278fdc-cdb0-4420-95ac-5ac6ed7a29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/completion.py\n",
    "import streamlit as st\n",
    "import pandas as pd  # Ensure pandas is imported\n",
    "from data_loader import load_data\n",
    "\n",
    "def show_completion_time(df):\n",
    "    st.title(\"Completion Time Analysis\")\n",
    "    \n",
    "    # Ensure the 'date_time' column is in datetime format\n",
    "    if 'date_time' not in df.columns:\n",
    "        st.error(\"Missing 'date_time' column in the dataset.\")\n",
    "        return\n",
    "    \n",
    "    # Coerce errors to NaT (Not a Time)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')  \n",
    "\n",
    "    # Drop rows where 'date_time' is NaT after coercion\n",
    "    df = df.dropna(subset=['date_time'])\n",
    "\n",
    "    # Sort the dataset to ensure chronological order by client_id, visit_id, and date_time\n",
    "    df = df.sort_values(by=['client_id', 'visit_id', 'date_time'])\n",
    "    \n",
    "    # Split the data into control and test groups\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "    \n",
    "    # Function to calculate completion time for each step considering multiple visits\n",
    "    def calculate_completion_time_with_visits(group_df):\n",
    "        group_df = group_df.sort_values(by=['client_id', 'visit_id', 'date_time'])\n",
    "        group_df['next_step_time'] = group_df.groupby(['client_id', 'visit_id'])['date_time'].shift(-1)\n",
    "        group_df = group_df.dropna(subset=['next_step_time'])\n",
    "        group_df['completion_time'] = group_df['next_step_time'] - group_df['date_time']\n",
    "        return group_df[['client_id', 'visit_id', 'process_step', 'date_time', 'next_step_time', 'completion_time']]\n",
    "\n",
    "    # Function to filter out outliers using IQR\n",
    "    def filter_outliers(group_df):\n",
    "        # Convert completion_time to minutes for easier interpretation\n",
    "        group_df['completion_time_minutes'] = group_df['completion_time'].dt.total_seconds() / 60\n",
    "        \n",
    "        # Calculate the IQR (Interquartile Range) for completion time\n",
    "        Q1 = group_df['completion_time_minutes'].quantile(0.25)\n",
    "        Q3 = group_df['completion_time_minutes'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define the upper and lower bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Filter out the outliers based on IQR\n",
    "        filtered_data = group_df[\n",
    "            (group_df['completion_time_minutes'] >= lower_bound) &\n",
    "            (group_df['completion_time_minutes'] <= upper_bound)\n",
    "        ]\n",
    "        return filtered_data\n",
    "\n",
    "    # Apply the function to both the control and test groups\n",
    "    control_group_completion_times = calculate_completion_time_with_visits(control_group)\n",
    "    test_group_completion_times = calculate_completion_time_with_visits(test_group)\n",
    "    \n",
    "    # Filter out outliers from both groups\n",
    "    control_group_filtered = filter_outliers(control_group_completion_times)\n",
    "    test_group_filtered = filter_outliers(test_group_completion_times)\n",
    "    \n",
    "    # Calculate the average completion time in minutes for each process step, after removing outliers\n",
    "    avg_completion_time_control = control_group_filtered.groupby('process_step')['completion_time_minutes'].mean().reset_index()\n",
    "    avg_completion_time_test = test_group_filtered.groupby('process_step')['completion_time_minutes'].mean().reset_index()\n",
    "    \n",
    "    # Display the results for control and test group average completion times\n",
    "    st.subheader(\"Average Completion Time for Control Group (Minutes) - After Outlier Removal\")\n",
    "    st.dataframe(avg_completion_time_control)\n",
    "\n",
    "    st.subheader(\"Average Completion Time for Test Group (Minutes) - After Outlier Removal\")\n",
    "    st.dataframe(avg_completion_time_test)\n",
    "    \n",
    "    # Display comparison of control vs test group average completion times\n",
    "    st.subheader(\"Comparison of Average Completion Time by Process Step\")\n",
    "    comparison_df = pd.merge(avg_completion_time_control, avg_completion_time_test, on='process_step', suffixes=('_control', '_test'))\n",
    "    st.dataframe(comparison_df)\n",
    "\n",
    "    # Optional: You could plot the results for better visualization if desired\n",
    "    # st.bar_chart(comparison_df.set_index('process_step')[['completion_time_minutes_control', 'completion_time_minutes_test']])\n",
    "\n",
    "    # Additional insights and interpretation\n",
    "    st.subheader(\"Insights & Interpretation\")\n",
    "    st.write(\"\"\"\n",
    "    In this section, we can derive insights based on the completion time across different groups and process steps:\n",
    "    \n",
    "    - **Completion Time Analysis**: Are there significant differences in the time it takes for each process step between the Control and Test groups?\n",
    "    - **Outlier Removal**: By removing outliers using the IQR method, we can focus on more representative data for process completion times.\n",
    "    - **Improvement in Test Group**: Does the Test group show faster completion times compared to the Control group after considering the removal of outliers?\n",
    "    \n",
    "    Please review the data and interpret the results to drive business decisions and process improvements.\n",
    "    \"\"\")\n",
    "\n",
    "    # **Process Duration Analysis**: Calculate process duration for start and confirm steps\n",
    "    st.subheader(\"Process Duration Analysis\")\n",
    "\n",
    "    # Filter to get the latest start for each client\n",
    "    starts_only = df[df['process_step'] == 'start']\n",
    "    latest_starts = starts_only.loc[starts_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Filter to get the last confirmation for each client\n",
    "    confirmation_only = df[df['process_step'] == 'confirm']\n",
    "    latest_confirms = confirmation_only.loc[confirmation_only.groupby('client_id')['date_time'].idxmax()]\n",
    "\n",
    "    # Merge to have both latest start and confirm per client\n",
    "    latest_start_confirms = pd.merge(latest_starts, latest_confirms, on='client_id', suffixes=('_start', '_confirm'))\n",
    "\n",
    "    # Calculate process duration for those who completed the process\n",
    "    latest_start_confirms['process_duration'] = latest_start_confirms['date_time_confirm'] - latest_start_confirms['date_time_start']\n",
    "\n",
    "    # Convert timedelta to seconds for easier manipulation\n",
    "    latest_start_confirms['process_duration_seconds'] = latest_start_confirms['process_duration'].dt.total_seconds()\n",
    "\n",
    "    # Calculate the IQR (Interquartile Range) for process duration\n",
    "    Q1_duration = latest_start_confirms['process_duration_seconds'].quantile(0.25)\n",
    "    Q3_duration = latest_start_confirms['process_duration_seconds'].quantile(0.75)\n",
    "    IQR_duration = Q3_duration - Q1_duration\n",
    "\n",
    "    # Define the upper and lower bounds for outliers in process duration\n",
    "    lower_bound_duration = Q1_duration - 1.5 * IQR_duration\n",
    "    upper_bound_duration = Q3_duration + 1.5 * IQR_duration\n",
    "\n",
    "    # Filter out the outliers based on IQR for process duration\n",
    "    filtered_duration_data = latest_start_confirms[\n",
    "        (latest_start_confirms['process_duration_seconds'] >= lower_bound_duration) &\n",
    "        (latest_start_confirms['process_duration_seconds'] <= upper_bound_duration)\n",
    "    ]\n",
    "\n",
    "    # Convert process_duration back to Timedelta\n",
    "    filtered_duration_data['process_duration'] = pd.to_timedelta(filtered_duration_data['process_duration_seconds'], unit='s')\n",
    "\n",
    "    # Calculate the average process duration again after removing outliers\n",
    "    st.subheader(\"Average Process Duration (Filtered) - After Outlier Removal\")\n",
    "    st.write(f\"Average process duration: {filtered_duration_data['process_duration'].mean()}\")\n",
    "    st.write(f\"Median process duration: {filtered_duration_data['process_duration'].median()}\")\n",
    "    \n",
    "    # Optional: Display filtered duration data\n",
    "    st.subheader(\"Filtered Process Duration Data (Outliers Removed)\")\n",
    "    st.dataframe(filtered_duration_data[['client_id', 'process_duration']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b8b39-13de-4087-b6a3-cc2fe1e80560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bounce_rate.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from data_loader import load_data\n",
    "\n",
    "# Function to calculate counts for z-test\n",
    "def calculate_counts(group):\n",
    "    steps = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "    counts = []  # Store counts as tuples (N_started, N_dropped)\n",
    "    \n",
    "    for i in range(len(steps) - 1):\n",
    "        current_step = steps[i]\n",
    "        next_step = steps[i + 1]\n",
    "        # Total users who started at this step\n",
    "        started = group[group['process_step'] == current_step]['client_id'].nunique()\n",
    "        # Total users who dropped off at this step\n",
    "        reached_next = group[group['process_step'] == next_step]['client_id'].nunique()\n",
    "        dropped = started - reached_next\n",
    "        counts.append((started, dropped))\n",
    "    \n",
    "    return counts\n",
    "\n",
    "# Function to perform two-proportion z-test\n",
    "def two_proportion_z_test(n1, x1, n2, x2):\n",
    "    # Calculate proportions\n",
    "    p1 = x1 / n1 if n1 > 0 else 0\n",
    "    p2 = x2 / n2 if n2 > 0 else 0\n",
    "    \n",
    "    # Pooled proportion\n",
    "    p = (x1 + x2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate z-statistic\n",
    "    z = (p1 - p2) / ((p * (1 - p) * (1 / n1 + 1 / n2)) ** 0.5)\n",
    "    \n",
    "    # Calculate two-tailed p-value\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z)))\n",
    "    \n",
    "    return z, p_value\n",
    "\n",
    "# Main function to display the bounce rate analysis page\n",
    "def show_bounce_rate(df):\n",
    "    st.title(\"Bounce Rate Analysis\")\n",
    "\n",
    "    # Ensure that the necessary columns exist in the dataframe\n",
    "    if 'clnt_age' not in df.columns or 'process_step' not in df.columns or 'client_id' not in df.columns:\n",
    "        st.error(\"Required columns ('clnt_age', 'process_step', 'client_id') are missing.\")\n",
    "        return\n",
    "    \n",
    "    # Create age groups based on 'clnt_age'\n",
    "    bins = [0, 30, 40, 50, 100]  # You can adjust the age bins as needed\n",
    "    labels = ['Under 30', '30-39', '40-49', '50 and above']\n",
    "    df['age_group'] = pd.cut(df['clnt_age'], bins=bins, labels=labels)\n",
    "    \n",
    "    # Split the data into Control and Test groups\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "    \n",
    "    # Sort Control and Test groups\n",
    "    control_group_sorted = control_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "    test_group_sorted = test_group.sort_values(by=['client_id', 'visit_id', 'process_step', 'date_time'])\n",
    "    \n",
    "    # Calculate the drop-off rates for both Control and Test groups\n",
    "    control_dropoff_rate = calculate_dropoff_rate(control_group_sorted)\n",
    "    test_dropoff_rate = calculate_dropoff_rate(test_group_sorted)\n",
    "\n",
    "    # Display Bounce Rates for Control and Test Groups\n",
    "    st.subheader(\"Bounce Rates for Control and Test Groups (Overall)\")\n",
    "    st.write(\"Control Group Bounce Rates (%):\")\n",
    "    for step, rate in control_dropoff_rate.items():\n",
    "        st.write(f\"{step}: {rate:.2f}%\")\n",
    "    \n",
    "    st.write(\"\\nTest Group Bounce Rates (%):\")\n",
    "    for step, rate in test_dropoff_rate.items():\n",
    "        st.write(f\"{step}: {rate:.2f}%\")\n",
    "    \n",
    "    # Calculate and display drop-off rates by Age Group for Control and Test groups\n",
    "    st.subheader(\"Bounce Rates by Age Group\")\n",
    "\n",
    "    control_dropoff_rate_by_age = calculate_dropoff_rate_by_age(control_group_sorted)\n",
    "    test_dropoff_rate_by_age = calculate_dropoff_rate_by_age(test_group_sorted)\n",
    "\n",
    "    # Display Control group drop-off rates by Age\n",
    "    st.write(\"Control Group Bounce Rates by Age Group:\")\n",
    "    for age_group, rates in control_dropoff_rate_by_age.items():\n",
    "        st.write(f\"Age Group: {age_group}\")\n",
    "        for step, rate in rates.items():\n",
    "            st.write(f\"  {step}: {rate:.2f}%\")\n",
    "    \n",
    "    # Display Test group drop-off rates by Age\n",
    "    st.write(\"Test Group Bounce Rates by Age Group:\")\n",
    "    for age_group, rates in test_dropoff_rate_by_age.items():\n",
    "        st.write(f\"Age Group: {age_group}\")\n",
    "        for step, rate in rates.items():\n",
    "            st.write(f\"  {step}: {rate:.2f}%\")\n",
    "\n",
    "    # **Hypothesis Testing (Z-Test) Section**\n",
    "    st.subheader(\"Hypothesis Test using Z-Test\")\n",
    "    \n",
    "    # Null Hypothesis: H‚ÇÄ = The bounce rates for the control and test groups are the same for a given step.\n",
    "    # Alternative Hypothesis: H‚ÇÅ = The bounce rates for the control and test groups are different for a given step.\n",
    "    \n",
    "    st.write(\"\"\"\n",
    "    **Null Hypothesis (H‚ÇÄ)**: The bounce rates for the control and test groups are the same for a given step.  \n",
    "    **Alternative Hypothesis (H‚ÇÅ)**: The bounce rates for the control and test groups are different for a given step.\n",
    "    \"\"\")\n",
    "\n",
    "    # Calculate counts for Control and Test groups\n",
    "    control_counts = calculate_counts(control_group_sorted)\n",
    "    test_counts = calculate_counts(test_group_sorted)\n",
    "\n",
    "    # Perform z-tests for each step and decide on hypothesis\n",
    "    z_test_results = []\n",
    "\n",
    "    steps = ['start', 'step_1', 'step_2', 'step_3']\n",
    "    for i, step in enumerate(steps):\n",
    "        n1, x1 = control_counts[i]  # Control group: (N_started, N_dropped)\n",
    "        n2, x2 = test_counts[i]     # Test group: (N_started, N_dropped)\n",
    "        \n",
    "        # Perform z-test for proportions\n",
    "        z_stat, p_value = two_proportion_z_test(n1, x1, n2, x2)\n",
    "        \n",
    "        # Decide whether to reject the null hypothesis\n",
    "        reject_null = p_value < 0.05\n",
    "        \n",
    "        # Store results\n",
    "        z_test_results.append({\n",
    "            'Step': step,\n",
    "            'Control Bounce Rate (%)': (x1 / n1) * 100 if n1 > 0 else 0,\n",
    "            'Test Bounce Rate (%)': (x2 / n2) * 100 if n2 > 0 else 0,\n",
    "            'Z-Statistic': z_stat,\n",
    "            'P-Value': p_value,\n",
    "            'Reject Null Hypothesis': reject_null\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame for display\n",
    "    z_test_results_df = pd.DataFrame(z_test_results)\n",
    "\n",
    "    # Display Z-Test Results\n",
    "    st.write(z_test_results_df)\n",
    "\n",
    "    # Optional: Provide a brief explanation of the Z-Test\n",
    "    st.write(\"\"\"\n",
    "    The Z-Test is used here to test if there is a significant difference between the bounce rates for the control and test groups at each process step.\n",
    "    \n",
    "    - A Z-Statistic closer to 0 indicates that the difference between the two groups is small.\n",
    "    - A p-value below 0.05 suggests that we reject the null hypothesis and conclude that the bounce rates are significantly different.\n",
    "    - If the p-value is greater than 0.05, we fail to reject the null hypothesis, meaning the bounce rates are similar.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447293be-8da0-4b34-9642-58ebc229a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pages/error_rate.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest, ttest_ind\n",
    "from data_loader import load_data\n",
    "\n",
    "# Function to calculate errors\n",
    "def calculate_errors(group):\n",
    "    group['step_index'] = group['process_step'].map({'start': 0, 'step_1': 1, 'step_2': 2, 'step_3': 3, 'confirm': 4})\n",
    "    group['error'] = group['step_index'].diff().apply(lambda x: x < 0)  # Negative diff indicates a backward step\n",
    "    return group\n",
    "\n",
    "# Function to calculate error rates for both groups\n",
    "def calculate_error_rates(control_group, test_group):\n",
    "    # Calculate errors\n",
    "    control_group = calculate_errors(control_group)\n",
    "    test_group = calculate_errors(test_group)\n",
    "\n",
    "    # Calculate Error Rates\n",
    "    control_error_rate = control_group['error'].mean() * 100\n",
    "    test_error_rate = test_group['error'].mean() * 100\n",
    "\n",
    "    # Error rate difference\n",
    "    error_rate_difference = control_error_rate - test_error_rate  # Difference between control and test error rates\n",
    "    threshold = 5  # 5% threshold for the difference\n",
    "\n",
    "    # Perform hypothesis testing: binomial test\n",
    "    control_errors = control_group['error'].sum()\n",
    "    control_total = len(control_group)\n",
    "    test_errors = test_group['error'].sum()\n",
    "    test_total = len(test_group)\n",
    "\n",
    "    # Perform a one-tailed binomial test\n",
    "    result = binomtest(test_errors, test_total, control_errors / control_total, alternative='less')\n",
    "\n",
    "    # Perform independent t-test for error rates\n",
    "    control_error_rate_values = control_group['error'].astype(int)\n",
    "    test_error_rate_values = test_group['error'].astype(int)\n",
    "\n",
    "    # Perform the independent t-test\n",
    "    t_stat, t_p_value = ttest_ind(control_error_rate_values, test_error_rate_values, equal_var=False, alternative='two-sided')\n",
    "\n",
    "    return {\n",
    "        'control_error_rate': control_error_rate,\n",
    "        'test_error_rate': test_error_rate,\n",
    "        'error_rate_difference': error_rate_difference,\n",
    "        'binomial_p_value': result.pvalue,\n",
    "        't_statistic': t_stat,\n",
    "        't_p_value': t_p_value,\n",
    "    }\n",
    "\n",
    "# Function to display the results\n",
    "def show_error_rate_analysis(df):\n",
    "    st.title(\"Error Rate Hypothesis Testing\")\n",
    "\n",
    "    # Split the data into control and test groups\n",
    "    control_group = df[df['variation'] == 'Control']\n",
    "    test_group = df[df['variation'] == 'Test']\n",
    "\n",
    "    # Calculate error rates and perform hypothesis testing\n",
    "    results = calculate_error_rates(control_group, test_group)\n",
    "\n",
    "    # Display results\n",
    "    st.subheader(\"Error Rates Comparison\")\n",
    "    st.write(f\"Control Group Error Rate: {results['control_error_rate']:.2f}%\")\n",
    "    st.write(f\"Test Group Error Rate: {results['test_error_rate']:.2f}%\")\n",
    "    st.write(f\"Error Rate Difference: {results['error_rate_difference']:.2f}%\")\n",
    "\n",
    "    # Display hypothesis testing results\n",
    "    st.subheader(\"Hypothesis Testing Results\")\n",
    "\n",
    "    # Binomial Test Results\n",
    "    st.write(f\"Binomial Test p-value: {results['binomial_p_value']:.4f}\")\n",
    "    if results['binomial_p_value'] < 0.05:\n",
    "        st.write(\"The test group has significantly lower error rate than the control group (p-value < 0.05).\")\n",
    "    else:\n",
    "        st.write(\"There is no significant difference in error rates between the test and control groups.\")\n",
    "\n",
    "    # T-test Results\n",
    "    st.write(f\"T-test Statistic: {results['t_statistic']:.4f}\")\n",
    "    st.write(f\"T-test p-value: {results['t_p_value']:.4f}\")\n",
    "    if results['t_p_value'] < 0.05:\n",
    "        st.write(\"There is a significant difference in error rates between the control and test groups.\")\n",
    "    else:\n",
    "        st.write(\"There is no significant difference in error rates between the control and test groups.\")\n",
    "\n",
    "    # Conclusion based on practical significance (error rate difference)\n",
    "    st.subheader(\"Practical Significance\")\n",
    "    if results['error_rate_difference'] >= 5:\n",
    "        st.write(\"The test group has at least a 5% lower error rate than the control group, which is practically significant.\")\n",
    "    else:\n",
    "        st.write(\"The error rate difference is less than 5%, which may not be practically significant for making decisions.\")\n",
    "\n",
    "    # Conclusion\n",
    "    st.subheader(\"Conclusion\")\n",
    "    if results['binomial_p_value'] < 0.05 and results['error_rate_difference'] >= 5:\n",
    "        st.write(\"The test group shows both statistical and practical significance. The improvement in error rates may justify action.\")\n",
    "    else:\n",
    "        st.write(\"Although the test group shows statistically significant differences, the practical significance (error rate difference) may not justify making significant changes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519591a6-0cc8-4ffd-976f-ba80bf5761ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee1a38-eb71-4ab2-a21c-9ad96f657e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167da054-1c91-4986-9375-59534cc6378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/display.py\n",
    "import streamlit as st\n",
    "from data_loader import load_data\n",
    "\n",
    "# Function to show an error message\n",
    "def show_error(message: str):\n",
    "    st.error(message)\n",
    "\n",
    "# Function to display a dataframe\n",
    "def display_dataframe(df, rows=5):\n",
    "    if df is not None:\n",
    "        st.dataframe(df.head(rows))\n",
    "    else:\n",
    "        show_error(\"Data is not available.\")\n",
    "\n",
    "# Function to display basic statistics of the dataframe\n",
    "def show_basic_statistics(df):\n",
    "    if df is not None:\n",
    "        numeric_df = df.select_dtypes(include=['number'])\n",
    "        if not numeric_df.empty:\n",
    "            st.subheader(\"Basic Statistics\")\n",
    "            st.write(numeric_df.describe().T)\n",
    "        else:\n",
    "            show_error(\"No numeric columns found for statistics.\")\n",
    "    else:\n",
    "        show_error(\"Data is not available for statistics.\")\n",
    "\n",
    "# Function to show unique values for categorical columns\n",
    "def show_unique_values(df):\n",
    "    if df is not None:\n",
    "        categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        if categorical_columns:\n",
    "            for column in categorical_columns:\n",
    "                st.write(f\"Column: {column}\")\n",
    "                st.write(f\"Unique values: {df[column].unique()}\")\n",
    "        else:\n",
    "            show_error(\"No categorical columns found.\")\n",
    "    else:\n",
    "        show_error(\"Data is not available for unique value display.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
